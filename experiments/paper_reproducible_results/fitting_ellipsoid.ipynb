{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/illusionww/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from itertools import combinations, product\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import powerlaw\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import colors\n",
    "from networkx.algorithms.community.quality import modularity as nx_modularity\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../../pygkernels')\n",
    "from pygkernels.measure import kernels\n",
    "from pygkernels.scenario import d3_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localizaton by SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_order = [x.name for x in kernels]\n",
    "list(enumerate(kernels_order));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/media/illusionww/68949C3149F4E819/phd/pygkernels/montecarlo_lfr_simple'\n",
    "# dataset = []\n",
    "# for fn in tqdm(os.listdir(root)):\n",
    "#     with open(f'{root}/{fn}', 'rb') as f:\n",
    "#         dataset.append(json.load(f))\n",
    "        \n",
    "with open('filtered_dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "idx_several_answers = [idx for idx, d in enumerate(dataset) \n",
    "                       if np.sum(np.max(np.array(list(d['measure_best_results'].values()))) == np.array(list(d['measure_best_results'].values()))) > 1]\n",
    "idx_several_answers = set(idx_several_answers)\n",
    "\n",
    "dataset = [d for idx, d in enumerate(dataset) if idx not in idx_several_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10.00, 1499.00 | 0.00, 1.00\n",
      "tau1|sqrtinv: 0.27, 0.94 | 0.00, 1.00\n",
      "tau2|sqrtinv: 0.19, 0.97 | 0.00, 1.00\n",
      "avg_degree|log: 0.86, 7.07 | 0.00, 1.00\n",
      "modularity: -0.46, 0.84 | 0.00, 1.00\n"
     ]
    }
   ],
   "source": [
    "lfr_feature_names = [\n",
    "    'n',\n",
    "    'tau1|sqrtinv',\n",
    "    'tau2|sqrtinv',\n",
    "#     'avg_density',\n",
    "    'avg_degree|log',\n",
    "    'modularity'\n",
    "]\n",
    "\n",
    "graph_feature_names = [\n",
    "    'n',\n",
    "    'tau1|sqrtinv',\n",
    "    'tau2|sqrtinv',\n",
    "#     'avg_density',\n",
    "    'avg_degree|log',\n",
    "    'modularity'\n",
    "]\n",
    "\n",
    "all_feature_names = [\n",
    "    'n',\n",
    "    'tau1|sqrtinv',\n",
    "    'tau2|sqrtinv',\n",
    "#     'avg_density',\n",
    "    'avg_degree|log',\n",
    "    'modularity'\n",
    "]\n",
    "\n",
    "top_feature_names = [\n",
    "    'n',\n",
    "    'tau1|sqrtinv',\n",
    "    'tau2|sqrtinv',\n",
    "#     'avg_density',\n",
    "    'avg_degree|log',\n",
    "    'modularity'\n",
    "]\n",
    "\n",
    "feature_min = {fn: np.min([data['estimated_params'][fn] for data in dataset]) for fn in all_feature_names}\n",
    "feature_max = {fn: np.max([data['estimated_params'][fn] for data in dataset]) for fn in all_feature_names}\n",
    "feature_width = {fn: feature_max[fn] - feature_min[fn] for fn in all_feature_names}\n",
    "feature_normalize = lambda x, fn: (x - feature_min[fn]) / feature_width[fn]\n",
    "\n",
    "for fn in all_feature_names:\n",
    "    print(f'{fn}: {feature_min[fn]:.2f}, {feature_max[fn]:.2f} | '\n",
    "          f'{feature_normalize(feature_min[fn], fn):.2f}, {feature_normalize(feature_max[fn], fn):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineModel(nn.Module):\n",
    "    def __init__(self, ndim):\n",
    "        super().__init__()\n",
    "#         print('ndim', ndim)\n",
    "        self.layer = nn.Linear(ndim, ndim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h = self.layer(X)\n",
    "        return (torch.clamp(1 - torch.sqrt(torch.sum(torch.pow(h, 2), dim=1)), -10, 1) + 1) / 2  # from -49.5 to 1, with border on 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y_true):\n",
    "    pos_weight, neg_weight = float(y_true.shape[0]) / torch.sum(y_true == 1).float() / 2, float(y_true.shape[0]) / torch.sum(y_true == 0).float() / 2\n",
    "#     print(pos_weight, neg_weight)\n",
    "    weights = y_true * pos_weight + (1 - y_true) * neg_weight\n",
    "    return torch.mean(weights * (y_pred - y_true) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipsoidEstimator:\n",
    "    def __init__(self, ndim, device=0):\n",
    "        self.device = device\n",
    "        self.model = AffineModel(ndim).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.model.layer.weight.fill_(0.)\n",
    "            for i in range(self.model.layer.weight.shape[0]):\n",
    "                self.model.layer.weight[i, i] = 1\n",
    "            self.model.layer.bias.fill_(0.5)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y_true = torch.from_numpy(X).float().to(self.device), torch.from_numpy(y).long().to(self.device)\n",
    "        \n",
    "        best_weights = {\n",
    "            'weight': None,\n",
    "            'bias': None\n",
    "        }\n",
    "        min_loss = 228*1488\n",
    "        optimizer = optim.Adam(params=self.model.parameters(), lr=0.001)\n",
    "        for n_epoch in range(10000):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.model(X)\n",
    "            loss = mse(y_pred, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss.detach()\n",
    "                with torch.no_grad():\n",
    "                    best_weights['weight'] = self.model.layer.weight.clone()\n",
    "                    best_weights['bias'] = self.model.layer.bias.clone()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.model.layer.weight = torch.nn.Parameter(best_weights['weight'])\n",
    "            self.model.layer.bias = torch.nn.Parameter(best_weights['bias'])\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = torch.from_numpy(X).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(X)\n",
    "        return y_pred.cpu().numpy()\n",
    "    \n",
    "    def fit_predict(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tx = np.array([[feature_normalize(item['estimated_params'][fname], fname) for fname in lfr_feature_names] for item in dataset]).astype(np.float32)\n",
    "ty = np.array([[item['measure_best_results'][kernel] for kernel in kernels_order] for item in dataset]).astype(np.float32)\n",
    "print(tx.shape, ty.shape)\n",
    "\n",
    "for kernel_name in ['SCCT', 'NHeat', 'Comm', 'RSP', 'logComm', 'SP-CT', 'DF', 'Katz', 'SCT', 'logDF', 'logKatz']:\n",
    "    measure_idx = kernels_order.index(kernel_name)\n",
    "    y_true = np.argmax(ty, axis=1) == measure_idx\n",
    "    \n",
    "    estimator = EllipsoidEstimator(tx.shape[1])\n",
    "    y_pred = estimator.fit_predict(tx, y_true)\n",
    "    f1 = f1_score(y_true, y_pred > 0.5)\n",
    "    \n",
    "    print(f'{kernel_name}\\t({measure_idx})\\t{np.sum(y_true)}\\t{f1:.2f}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tx = np.array([[feature_normalize(item['estimated_params'][fname], fname) for fname in graph_feature_names] for item in dataset]).astype(np.float32)\n",
    "ty = np.array([[item['measure_best_results'][kernel] for kernel in kernels_order] for item in dataset]).astype(np.float32)\n",
    "print(tx.shape, ty.shape)\n",
    "\n",
    "for kernel_name in ['SCCT', 'NHeat', 'Comm', 'RSP', 'logComm', 'SP-CT', 'DF', 'Katz', 'SCT', 'logDF', 'logKatz']:\n",
    "    measure_idx = kernels_order.index(kernel_name)\n",
    "    y_true = np.argmax(ty, axis=1) == measure_idx\n",
    "    \n",
    "    estimator = EllipsoidEstimator(tx.shape[1])\n",
    "    y_pred = estimator.fit_predict(tx, y_true)\n",
    "    f1 = f1_score(y_true, y_pred > 0.5)\n",
    "    \n",
    "    print(f'{kernel_name}\\t({measure_idx})\\t{np.sum(y_true)}\\t{f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5360, 5) (5360, 25)\n"
     ]
    }
   ],
   "source": [
    "tx = np.array([[feature_normalize(item['estimated_params'][fname], fname) for fname in all_feature_names] for item in dataset]).astype(np.float32)\n",
    "ty = np.array([[item['measure_best_results'][kernel] for kernel in kernels_order] for item in dataset]).astype(np.float32)\n",
    "print(tx.shape, ty.shape)\n",
    "\n",
    "# for kernel_name in ['SCCT', 'NHeat', 'Comm', 'RSP', 'logComm', 'SP-CT', 'DF', 'Katz', 'SCT', 'logDF', 'logKatz']:\n",
    "#     measure_idx = kernels_order.index(kernel_name)\n",
    "#     y_true = np.argmax(ty, axis=1) == measure_idx\n",
    "    \n",
    "#     estimator = EllipsoidEstimator(tx.shape[1])\n",
    "#     y_pred = estimator.fit_predict(tx, y_true)\n",
    "#     f1 = f1_score(y_true, y_pred > 0.5)\n",
    "    \n",
    "#     print(f'{kernel_name}\\t({measure_idx})\\t{np.sum(y_true)}\\t{f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best 2d projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFE:\n",
    "    def __init__(self, feature_names, max_features=2, n_jobs=4):\n",
    "        self.feature_names = feature_names\n",
    "        self.max_features = max_features\n",
    "        self.n_jobs = n_jobs\n",
    "        self.results = {}\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def score_one(self, X, y_true, set_feat_names, device=0):\n",
    "        support = np.array([x in set_feat_names for x in self.feature_names], dtype=np.bool)\n",
    "        estimator = EllipsoidEstimator(ndim=np.sum(support), device=device)\n",
    "#         print(X[:, support].shape, y_true.shape)\n",
    "        y_pred = estimator.fit_predict(X[:, support], y_true)\n",
    "#         print(y_pred.shape)\n",
    "        f1 = f1_score(y_true, y_pred > 0.5)\n",
    "        return set_feat_names, f1, estimator\n",
    "\n",
    "    def fit(self, X, y_true):\n",
    "        # for all features first:\n",
    "        _, f1_all, estimator_all = self.score_one(X, y_true, self.feature_names)\n",
    "        print(f'all features, f1={f1_all:.3f}')\n",
    "\n",
    "#         for n_features in range(self.max_features, self.max_features + 1):\n",
    "#             raw_results = Parallel(n_jobs=self.n_jobs)(delayed(self.score_one)(X, y_true, set_feat_names, idx % 2)\n",
    "#                                                    for idx, set_feat_names in enumerate(tqdm(list(combinations(self.feature_names, n_features)))))\n",
    "#             results = {\n",
    "#                 'lfr': {'best': {'set': None, 'f1': 0}, 'all_results': []},\n",
    "#                 'graphstructure': {'best': {'set': None, 'f1': 0}, 'all_results': []},\n",
    "#                 'all': {'best': {'set': None, 'f1': 0}, 'all_results': []},\n",
    "#             }\n",
    "#             for set_feat_names, f1, estimator in raw_results:\n",
    "#                 item = {'set': set_feat_names, 'f1': f1}\n",
    "#                 if all([name in lfr_feature_names for name in set_feat_names]):\n",
    "#                     results['lfr']['all_results'].append(item)\n",
    "#                     if f1 > results['lfr']['best']['f1']:\n",
    "#                         results['lfr']['best'] = item\n",
    "#                 if all([name in graph_feature_names for name in set_feat_names]):\n",
    "#                     results['graphstructure']['all_results'].append(item)\n",
    "#                     if f1 > results['graphstructure']['best']['f1']:\n",
    "#                         results['graphstructure']['best'] = item\n",
    "#                 results['all']['all_results'].append(item)\n",
    "#                 if f1 > results['all']['best']['f1']:\n",
    "#                     results['all']['best'] = item\n",
    "#             print(f\"{n_features} features\")\n",
    "#             print(f\"lfr, f1={results['lfr']['best']['f1']:.3f}, set={results['lfr']['best']['set']}\")\n",
    "#             print(f\"graphstructure, f1={results['graphstructure']['best']['f1']:.3f}, set={results['graphstructure']['best']['set']}\")\n",
    "#             print(f\"all, f1={results['all']['best']['f1']:.3f}, set={results['all']['best']['set']}\")\n",
    "#             self.results[n_features] = results\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5360, 5) (5360, 25)\n",
      "SCCT\n",
      "all features, f1=0.782\n",
      "\n",
      "NHeat\n",
      "all features, f1=0.434\n",
      "\n",
      "Comm\n",
      "all features, f1=0.246\n",
      "\n",
      "RSP\n",
      "all features, f1=0.122\n",
      "\n",
      "logComm\n",
      "all features, f1=0.301\n",
      "\n",
      "SP-CT\n",
      "all features, f1=0.081\n",
      "\n",
      "SCT\n",
      "all features, f1=0.100\n",
      "\n",
      "logDF\n",
      "all features, f1=0.222\n",
      "\n",
      "logKatz\n",
      "all features, f1=0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tx = np.array([[feature_normalize(item['estimated_params'][fname], fname) for fname in all_feature_names] for item in dataset]).astype(np.float32)\n",
    "ty = np.array([[item['measure_best_results'][kernel] for kernel in kernels_order] for item in dataset]).astype(np.float32)\n",
    "print(tx.shape, ty.shape)\n",
    "\n",
    "all_estimators = {}\n",
    "\n",
    "for kernel_name in [\n",
    "    'SCCT',\n",
    "    'NHeat',\n",
    "    'Comm',\n",
    "    'RSP',\n",
    "    'logComm',\n",
    "    'SP-CT',\n",
    "    'SCT',\n",
    "    'logDF',\n",
    "    'logKatz'\n",
    "]:\n",
    "    print(kernel_name)\n",
    "    measure_idx = kernels_order.index(kernel_name)\n",
    "    y_true = np.argmax(ty, axis=1) == measure_idx\n",
    "    \n",
    "    estimator = RFE(all_feature_names, max_features=5)\n",
    "    estimator.fit(tx, y_true)\n",
    "    \n",
    "    all_estimators[kernel_name] = estimator\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw2d(self, X, y_true):\n",
    "    set_feat_names, f1, estimator = self.results[2]['set'], self.results[2]['f1'], self.results[2]['estimator']\n",
    "    support = np.array([x in set_feat_names for x in self.feature_names], dtype=np.bool)\n",
    "    support_idx = [x for x in range(support.shape[0]) if support[x]]\n",
    "#         print(set_feat_names)\n",
    "#         print(support)\n",
    "#         print(support_idx)\n",
    "\n",
    "    y_pred = estimator.predict(X[:, support])\n",
    "    f1 = f1_score(y_true, y_pred > 0.5)\n",
    "    print(f'f1: {f1:.3f}')\n",
    "\n",
    "    background = np.zeros((101, 101, 3), dtype=np.uint8)\n",
    "    background[:] = 255\n",
    "    flatgrid = np.array(list(product(np.array(range(101)), np.array(range(101)))), dtype=np.int)\n",
    "    flatgrid2 = np.array(list(product(np.array(range(101)) / 100, np.array(range(101)) / 100)), dtype=np.float32)\n",
    "    background_flat = estimator.predict(flatgrid2)\n",
    "    for a, b in zip(flatgrid, background_flat):\n",
    "        if b > 0.5:\n",
    "            background[a[1], a[0], :] = 128\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    ax.imshow(background)\n",
    "\n",
    "    ax.scatter(X[:, support_idx[0]] * 100, X[:, support_idx[1]] * 100, s=1, c=y_true)\n",
    "\n",
    "    ax.set_xlabel(set_feat_names[0])\n",
    "    ax.set_ylabel(set_feat_names[1])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
