{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from networkx.algorithms.approximation import clique\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, LinearSVR\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from utils import (\n",
    "    SBM_Data,\n",
    "    Datasets_Data,\n",
    "    load_or_calc_and_save,\n",
    "    ytrue_to_partition,\n",
    "    calc_avranks,\n",
    "    RFE,\n",
    "    RFE_LOO,\n",
    "    OneVsRest_custom,\n",
    "    OneHotEncoding_custom,\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../pygkernels\")\n",
    "from pygkernels.scenario import d3_category20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prepare columns: 100%|██████████| 91/91 [00:00<00:00, 915.89it/s]\n",
      "prepare columns: 100%|██████████| 24/24 [00:00<00:00, 2869.45it/s]\n",
      "prepare columns: 100%|██████████| 91/91 [00:00<00:00, 601.65it/s]\n",
      "prepare columns: 100%|██████████| 24/24 [00:00<00:00, 3424.97it/s]\n"
     ]
    }
   ],
   "source": [
    "sbm_data_hub, datasets_data_hub = SBM_Data(), Datasets_Data()\n",
    "\n",
    "X_trainval, ari_trainval = sbm_data_hub.make_dataset(return_clf=False)\n",
    "X_test, ari_test = datasets_data_hub.make_dataset(return_clf=False)\n",
    "_, y_trainval = sbm_data_hub.make_dataset(return_clf=True)\n",
    "_, y_test = datasets_data_hub.make_dataset(return_clf=True)\n",
    "\n",
    "X_trainval_flat = X_trainval.reshape(-1, X_trainval.shape[2])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[2])\n",
    "y_trainval_flat = y_trainval.reshape(-1, y_trainval.shape[2])\n",
    "y_test_flat = y_test.reshape(-1, y_test.shape[2])\n",
    "ari_trainval_flat = ari_trainval.reshape(-1, ari_trainval.shape[2])\n",
    "ari_test_flat = ari_test.reshape(-1, ari_test.shape[2])\n",
    "\n",
    "feature_names = sbm_data_hub.allowed_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_feature_names = [\"n\", \"k\", \"p_in\", \"p_out\"]\n",
    "\n",
    "chosen_features = []\n",
    "for chosen_feature in chosen_feature_names:\n",
    "    chosen_features.append(sbm_data_hub.allowed_features_list.index(chosen_feature))\n",
    "chosen_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_kernels = np.array([False, True, True, True, False, True, True, True, False,\n",
    "                            False, True, True, True, False, False, False, True, True,\n",
    "                            True, True, False, False, False, False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: the best measure for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 1. best: logHeat (7), trainval: 0.683, test: 0.662\n"
     ]
    }
   ],
   "source": [
    "baseline1_kernel_idx = np.argmax(np.mean(ari_trainval_flat, axis=0))\n",
    "baseline1_trainval_ari = np.mean(ari_trainval_flat[:, baseline1_kernel_idx])\n",
    "baseline1_test_ari = np.mean(ari_test_flat[:, baseline1_kernel_idx])\n",
    "\n",
    "baseline1_kernel_name = sbm_data_hub.kernel_names[baseline1_kernel_idx]\n",
    "print(f\"baseline 1. best: {baseline1_kernel_name} ({baseline1_kernel_idx}), \"\n",
    "      f\"trainval: {baseline1_trainval_ari:.3f}, test: {baseline1_test_ari:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper bound 1: the best measure for all (by test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper bound 1. best: SCT (10), trainval: 0.678, test: 0.687\n"
     ]
    }
   ],
   "source": [
    "upperbound1_kernel_idx = np.argmax(np.mean(ari_test_flat, axis=0))\n",
    "upperbound1_trainval_ari = np.mean(ari_trainval_flat[:, upperbound1_kernel_idx])\n",
    "upperbound1_test_ari = np.mean(ari_test_flat[:, upperbound1_kernel_idx])\n",
    "\n",
    "upperbound1_kernel_name = sbm_data_hub.kernel_names[upperbound1_kernel_idx]\n",
    "print(f'upper bound 1. best: {upperbound1_kernel_name} ({upperbound1_kernel_idx}), '\n",
    "      f'trainval: {upperbound1_trainval_ari:.3f}, test: {upperbound1_test_ari:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper bound 2: the best measure for every graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper bound 2. trainval: 0.740, test: 0.710\n"
     ]
    }
   ],
   "source": [
    "upperbound2_trainval_ari = np.mean(np.max(ari_trainval_flat, axis=1))\n",
    "upperbound2_test_ari = np.mean(np.max(ari_test_flat, axis=1))\n",
    "print(f'upper bound 2. trainval: {upperbound2_trainval_ari:.3f}, test: {upperbound2_test_ari:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ours PRELIMINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6127777837053888"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = OneVsRest_custom(SVR(), weight_samples=True)\n",
    "estimator.fit(X_trainval_flat[:, chosen_features], ari_trainval_flat[:, support_kernels])\n",
    "y_pred = estimator.predict(X_test_flat[:, chosen_features])\n",
    "ours7 = np.mean(ari_test_flat[:, support_kernels][range(y_pred.shape[0]), np.argmax(y_pred, axis=1)])\n",
    "ours7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all features, acc=-1.000, f1=-1.000, ari=0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 142.47it/s]\n",
      "  0%|          | 0/171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 features, acc=-1.000, f1=-1.000, ari=0.611, set=('modularity',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [12:18<00:00,  4.32s/it]\n",
      "  0%|          | 0/969 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 features, acc=-1.000, f1=-1.000, ari=0.641, set=('k', 'p_in')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 969/969 [1:08:57<00:00,  4.27s/it]\n",
      "  0%|          | 0/3876 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 features, acc=-1.000, f1=-1.000, ari=0.645, set=('p_out', 'modularity', 'std_sp')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3841/3876 [4:11:59<02:47,  4.80s/it]  "
     ]
    }
   ],
   "source": [
    "estimator = OneVsRest_custom(SVC(), weight_samples=False)\n",
    "selector = RFE(estimator, feature_names, max_features=4, n_jobs=12)\n",
    "selector = selector.fit(X_trainval_flat, y_trainval_flat, X_test_flat, y_test_flat, ari_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ours MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_ari = defaultdict(list)\n",
    "for train_index, test_index in LeaveOneOut().split(X_trainval):\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "    \n",
    "    estimator = OneVsRest_custom(SVR(), weight_samples=True)\n",
    "    estimator.fit(X_train[:, chosen_features], ari_train[:, support_kernels])\n",
    "    y_pred = estimator.predict(X_val[:, chosen_features])\n",
    "    ours7 = np.mean(ari_val[:, support_kernels][range(y_pred.shape[0]), np.argmax(y_pred, axis=1)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
