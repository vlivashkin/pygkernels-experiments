{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from pygraphs.measure import kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = lambda x: sorted(x, key=lambda k: random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kkmeans init experiments, results\n",
    "\n",
    "Final goal: compare both different initialization (one, all, k-means++, any) and initialization quality measures (inertia, modularity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_ROOT = '/home/illusionww/Documents/HDD/phd/pygraphs/kkmeans_init_sbm/by_column_and_kernel'\n",
    "columns = [\n",
    "    (100, 2, 0.2, 0.05),\n",
    "    (100, 2, 0.3, 0.05),\n",
    "    (100, 2, 0.3, 0.1),\n",
    "    (100, 2, 0.3, 0.15),\n",
    "    (102, 3, 0.3, 0.1),\n",
    "    (100, 4, 0.3, 0.1),\n",
    "    (100, 4, 0.3, 0.15),\n",
    "    (200, 2, 0.3, 0.05),\n",
    "    (200, 2, 0.3, 0.1),\n",
    "    (200, 2, 0.3, 0.15),\n",
    "    (201, 3, 0.3, 0.1),\n",
    "    (200, 4, 0.3, 0.1),\n",
    "    (200, 4, 0.3, 0.15)\n",
    "]\n",
    "kernels_names = [\n",
    "    'pWalk', 'Walk',\n",
    "    'For', 'logFor',\n",
    "    'Comm', 'logComm',\n",
    "    'Heat', 'logHeat',\n",
    "    'NHeat', 'logNHeat',\n",
    "    'SCT', 'SCCT',\n",
    "    'RSP', 'FE',\n",
    "    'PPR', 'logPPR',\n",
    "    'ModifPPR', 'logModifPPR',\n",
    "    'HeatPR', 'logHeatPR',\n",
    "    'DF', 'logDF',\n",
    "    'Abs', 'logAbs',\n",
    "    'SP-CT'\n",
    "]\n",
    "init_names=['one', 'all', 'kmp', 'any', 'any2', 'best']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test\n",
    "n, k, p_in, p_out = columns[0]\n",
    "column_str = f'{n}_{k}_{p_in:.1f}_{p_out:.2f}'\n",
    "kernel_name = 'Comm'\n",
    "with open(f'{CACHE_ROOT}/{column_str}_{kernel_name}_results.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "len(data[0]['results'][0.0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cached_files = {}\n",
    "def request_cache(filename):\n",
    "    if filename not in cached_files:\n",
    "        with open(f'{CACHE_ROOT}/{filename}', 'rb') as f:\n",
    "            cached_files[filename] = pickle.load(f)\n",
    "    return cached_files[filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация, дающая наилучший результат\n",
    "\n",
    "Для каждого графа определяем наилучшую инициализацию **для каждого параметра** (по inertia, ARI и NMI). После этого считаем статистику внутри каждого графа, сколько побед у каждого типа инициализаций (one, all, k-kmeans++), выбираем победителя для графа. После этого считаем статистику для всех графов, выбираем победителя. Делаем это для каждой меры и каждого сетапа генерации графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_inits(param_results):\n",
    "    \"\"\"\n",
    "    * Сначала группируем инициализации по one, all, k-kmeans++, any,\n",
    "    * Потом для каждой группы выбираем лучшую согласно inertia или modularity\n",
    "    \"\"\"\n",
    "    one_inits = shuffle([x for x in param_results if x['init'] == 'one'])\n",
    "    all_inits = shuffle([x for x in param_results if x['init'] == 'all'])\n",
    "    kmp_inits = shuffle([x for x in param_results if x['init'] == 'k-means++'])\n",
    "    if len(one_inits) == 0 or len(all_inits) == 0 or len(kmp_inits) == 0:\n",
    "        return None\n",
    "    \n",
    "    best_ari_init = one_inits[0]\n",
    "    for init in one_inits + all_inits + kmp_inits:\n",
    "        if init['score_ari'] > best_ari_init['score_ari']:\n",
    "            best_ari_init = init\n",
    "    \n",
    "    init_results = {\n",
    "        'one': one_inits,\n",
    "        'all': all_inits,\n",
    "        'kmp': kmp_inits,\n",
    "        'any': one_inits[:10] + all_inits[:10] + kmp_inits[:10],\n",
    "        'any2': all_inits[:15] + kmp_inits[:15],\n",
    "        'best': [best_ari_init]\n",
    "    }\n",
    "    \n",
    "    bestby = {\n",
    "        'one': {'inertia': init_results['one'][0], 'modularity': init_results['one'][0]},\n",
    "        'all': {'inertia': init_results['all'][0], 'modularity': init_results['all'][0]},\n",
    "        'kmp': {'inertia': init_results['kmp'][0], 'modularity': init_results['kmp'][0]},\n",
    "        'any': {'inertia': init_results['any'][0], 'modularity': init_results['any'][0]},\n",
    "        'any2': {'inertia': init_results['any2'][0], 'modularity': init_results['any2'][0]},\n",
    "        'best': {'inertia': init_results['best'][0], 'modularity': init_results['best'][0]}\n",
    "    }\n",
    "    for init_name, inits in init_results.items():\n",
    "        for init in inits:\n",
    "            if init['inertia'] < bestby[init_name]['inertia']['inertia']:  # choose best by inertia\n",
    "                bestby[init_name]['inertia'] = init\n",
    "            if init['modularity'] > bestby[init_name]['modularity']['modularity']:  # choose best by modularity\n",
    "                bestby[init_name]['modularity'] = init\n",
    "    return bestby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_column_kernel_internal(data, score_name='score_ari'):\n",
    "    reaching_value = dict([(f'inertia_{x}', 0) for x in init_names] + [(f'modularity_{x}', 0) for x in init_names])\n",
    "    best_scores = dict([(f'inertia_{x}', []) for x in init_names] + [(f'modularity_{x}', []) for x in init_names])\n",
    "    for graph_idx, graph_results in enumerate(data):\n",
    "        graph_results = graph_results['results']\n",
    "        best_score = dict([(f'inertia_{x}', 0) for x in init_names] + [(f'modularity_{x}', 0) for x in init_names])\n",
    "        # choose best score accross kernel param\n",
    "        for param, param_results in graph_results.items():\n",
    "            bestby = group_inits(param_results)\n",
    "            if bestby is not None:\n",
    "                for unsup, init_name in product(['inertia', 'modularity'], init_names):\n",
    "                    try:\n",
    "                        score = bestby[init_name][unsup][score_name]\n",
    "                    except Exception as e:\n",
    "                        print(f'graph_idx: {graph_idx}, param: {param}, init: {init_name}, unsup: {unsup}')\n",
    "                        print(f'best_init: {bestby[init_name][unsup]}')\n",
    "                        raise e\n",
    "                    if score > best_score[f'{unsup}_{init_name}']:\n",
    "                        best_score[f'{unsup}_{init_name}'] = score\n",
    "        for unsup, init_name in product(['inertia', 'modularity'], init_names):\n",
    "            best_scores[f'{unsup}_{init_name}'].append(best_score[f'{unsup}_{init_name}'])\n",
    "            \n",
    "        # add 1 if setup reaches maximum\n",
    "        max_value = max(best_score.values())\n",
    "        for unsup, init_name in product(['inertia', 'modularity'], init_names):\n",
    "            reaching_value[f'{unsup}_{init_name}'] += best_score[f'{unsup}_{init_name}'] == max_value\n",
    "    \n",
    "    mean_scores = {}\n",
    "    for unsup, init_name in product(['inertia', 'modularity'], init_names):\n",
    "        mean_scores[f'{unsup}_{init_name}'] = np.mean(best_scores[f'{unsup}_{init_name}'])\n",
    "    \n",
    "    return reaching_value, mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673daf6f3cfe4a6e89a9444cceacb413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=325), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_column_kernel(column, kernel_name):\n",
    "    n, k, p_in, p_out = column\n",
    "    column_str = f'{n}_{k}_{p_in:.1f}_{p_out:.2f}'\n",
    "    filename = f'{column_str}_{kernel_name}_results.pkl'\n",
    "#     print(f'{column_str}, {kernel_name}')\n",
    "#     data = request_cache(filename)\n",
    "    with open(f'{CACHE_ROOT}/{filename}', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    reaching_value, mean_scores = perform_column_kernel_internal(data)\n",
    "    return (column_str, kernel_name), {\n",
    "        'reaching_value': reaching_value,\n",
    "        'mean_scores': mean_scores\n",
    "    }\n",
    "\n",
    "results = defaultdict(lambda: dict())\n",
    "raw_results = Parallel(n_jobs=2)(delayed(perform_column_kernel)(column, kernel_name)\n",
    "                                  for column, kernel_name in tqdm(list(product(columns, kernels_names))))\n",
    "for (column_str, kernel_name), result in raw_results:\n",
    "    results[column_str][kernel_name] = result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(results), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print as table\n",
    "\n",
    "with open('reaching_value.tsv', 'w') as f:\n",
    "    f.write('\\t')\n",
    "    for column in columns:\n",
    "        for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "            f.write(f'{column}\\t')\n",
    "    f.write('\\n\\t')\n",
    "    for column in columns:\n",
    "        for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "            f.write(f'{init_name}\\t')\n",
    "    f.write('\\n')\n",
    "    for kernel_name in kernels_names:\n",
    "        f.write(f'{kernel_name}\\t')\n",
    "        for column in columns:\n",
    "            n, k, p_in, p_out = column\n",
    "            column_str = f'{n}_{k}_{p_in:.1f}_{p_out:.2f}'\n",
    "            for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "                f.write(f'{results[column_str][kernel_name][\"reaching_value\"][init_name]}\\t')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mean_scores.tsv', 'w') as f:\n",
    "    f.write('\\t')\n",
    "    for column in columns:\n",
    "        for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "            f.write(f'{column}\\t')\n",
    "    f.write('\\n\\t')\n",
    "    for column in columns:\n",
    "        for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "            f.write(f'{init_name}\\t')\n",
    "    f.write('\\n')\n",
    "    for kernel_name in kernels_names:\n",
    "        f.write(f'{kernel_name}\\t')\n",
    "        for column in columns:\n",
    "            n, k, p_in, p_out = column\n",
    "            column_str = f'{n}_{k}_{p_in:.1f}_{p_out:.2f}'\n",
    "            for init_name in [f'inertia_{x}' for x in init_names] + [f'modularity_{x}' for x in init_names]:\n",
    "                f.write(f'{results[column_str][kernel_name][\"mean_scores\"][init_name]}\\t')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
