{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from pygraphs.measure import kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = lambda x: sorted(x, key=lambda k: random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kkmeans init experiments, results\n",
    "\n",
    "Final goal: compare both different initialization (one, all, k-means++, any) and initialization quality measures (inertia, modularity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_ROOT = '/home/illusionww/Documents/HDD/phd/pygraphs/kkmeans_init_sbm/by_column_and_kernel'\n",
    "columns = [\n",
    "    (100, 2, 0.2, 0.05),\n",
    "    (100, 2, 0.3, 0.05),\n",
    "    (100, 2, 0.3, 0.1),\n",
    "    (100, 2, 0.3, 0.15),\n",
    "    (102, 3, 0.3, 0.1),\n",
    "    (100, 4, 0.3, 0.1),\n",
    "    (100, 4, 0.3, 0.15),\n",
    "    (200, 2, 0.3, 0.05),\n",
    "    (200, 2, 0.3, 0.1),\n",
    "    (200, 2, 0.3, 0.15),\n",
    "    (201, 3, 0.3, 0.1),\n",
    "    (200, 4, 0.3, 0.1),\n",
    "    (200, 4, 0.3, 0.15)\n",
    "]\n",
    "kernels_names = [\n",
    "    'pWalk', 'Walk',\n",
    "    'For', 'logFor',\n",
    "    'Comm', 'logComm',\n",
    "    'Heat', 'logHeat',\n",
    "    'NHeat', 'logNHeat',\n",
    "    'SCT', 'SCCT',\n",
    "    'RSP', 'FE',\n",
    "    'PPR', 'logPPR',\n",
    "    'ModifPPR', 'logModifPPR',\n",
    "    'HeatPR', 'logHeatPR',\n",
    "    'DF', 'logDF',\n",
    "    'Abs', 'logAbs',\n",
    "    'SP-CT'\n",
    "]\n",
    "init_names=['one', 'all', 'kmp', 'any', 'any2', 'best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация, дающая наилучший результат\n",
    "\n",
    "Для каждого графа определяем наилучшую инициализацию **для каждого параметра** (по inertia, ARI и NMI). После этого считаем статистику внутри каждого графа, сколько побед у каждого типа инициализаций (one, all, k-kmeans++), выбираем победителя для графа. После этого считаем статистику для всех графов, выбираем победителя. Делаем это для каждой меры и каждого сетапа генерации графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_inits(param_results):\n",
    "    \"\"\"\n",
    "    * Сначала группируем инициализации по one, all, k-kmeans++, any,\n",
    "    * Потом для каждой группы выбираем лучшую согласно inertia или modularity\n",
    "    \"\"\"\n",
    "    one_inits = shuffle([x for x in param_results if x['init'] == 'one'])\n",
    "    all_inits = shuffle([x for x in param_results if x['init'] == 'all'])\n",
    "    kmp_inits = shuffle([x for x in param_results if x['init'] == 'k-means++'])\n",
    "    if len(one_inits) == 0 or len(all_inits) == 0 or len(kmp_inits) == 0:\n",
    "        return None\n",
    "    \n",
    "    bestby_any3_modularity = one_inits[0]\n",
    "    for init in one_inits[:10] + all_inits[:10] + kmp_inits[:10]:\n",
    "        if init['modularity'] > bestby_any3_modularity['modularity']:  # choose best by modularity\n",
    "            bestby_any3_modularity = init\n",
    "    return bestby_any3_modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_column_kernel_internal(data, score_name='score_ari'):\n",
    "    best_scores = []\n",
    "    for graph_idx, graph_results in enumerate(data):\n",
    "        graph_results = graph_results['results']\n",
    "        \n",
    "        # choose best score accross kernel param\n",
    "        best_score = -1\n",
    "        for param, param_results in graph_results.items():\n",
    "            bestby_any3_modularity = group_inits(param_results)\n",
    "            if bestby_any3_modularity is not None:\n",
    "                    score = bestby_any3_modularity[score_name]\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "        best_scores.append(best_score)\n",
    "    return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef5461746cc4e2a952d6dea5cc5aa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=325), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_column_kernel(column, kernel_name):\n",
    "    n, k, p_in, p_out = column\n",
    "    column_str = f'{n}_{k}_{p_in:.1f}_{p_out:.2f}'\n",
    "    filename = f'{column_str}_{kernel_name}_results.pkl'\n",
    "    with open(f'{CACHE_ROOT}/{filename}', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    all_scores = perform_column_kernel_internal(data)\n",
    "    return (column_str, kernel_name), all_scores\n",
    "\n",
    "results = defaultdict(lambda: dict())\n",
    "raw_results = Parallel(n_jobs=6)(delayed(perform_column_kernel)(column, kernel_name)\n",
    "                                  for column, kernel_name in tqdm(list(product(columns, kernels_names))))\n",
    "for (column_str, kernel_name), result in raw_results:\n",
    "    results[column_str][kernel_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print as table\n",
    "with open('sbm_all_data_for_cd2.csv', 'w') as f:\n",
    "    f.write('classifier_name,dataset_name,accuracy\\n')\n",
    "    for dataset_name, dataset_data in results.items():\n",
    "        for measure_name, measure_data in dataset_data.items():\n",
    "            for trial_idx, trial_ari in enumerate(measure_data):\n",
    "                f.write(f'{measure_name},{dataset_name},{trial_ari}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
