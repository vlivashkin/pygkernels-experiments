{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import networkx as nx\n",
    "from networkx.algorithms.approximation import clique\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import Orange\n",
    "import matplotlib\n",
    "from matplotlib.cm import coolwarm, Spectral_r\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, label_ranking_average_precision_score\n",
    "from sklearn.svm import SVR\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('../../pygkernels')\n",
    "from pygkernels.data import Datasets\n",
    "\n",
    "from sbm_neighbour_score import sbm_neighbour_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_names = [\n",
    "    'Katz', 'logKatz',\n",
    "    'For', 'logFor',\n",
    "    'Comm', 'logComm',\n",
    "    'Heat', 'logHeat',\n",
    "    'NHeat', 'logNHeat',\n",
    "    'SCT', 'SCCT',\n",
    "    'RSP', 'FE',\n",
    "    'PPR', 'logPPR',\n",
    "    'ModifPPR', 'logModifPPR',\n",
    "    'HeatPR', 'logHeatPR',\n",
    "    'DF', 'logDF',\n",
    "    'Abs', 'logAbs',\n",
    "    'SP-CT'\n",
    "]\n",
    "\n",
    "shuffle = lambda x: sorted(x, key=lambda k: random.random())\n",
    "\n",
    "def dict_argmax(dct, score_key):\n",
    "    best_key = list(dct.keys())[0]\n",
    "    best_val = dct[best_key]\n",
    "    for k, v in dct.items():\n",
    "        if v[score_key] > best_val[score_key]:\n",
    "            best_key, best_val = k, v\n",
    "    return best_key, best_val\n",
    "\n",
    "CACHE_ROOT = '../../cache/cache'\n",
    "\n",
    "def load_or_calc_and_save(filename, force_calc=False, ignore_if_exist=False):\n",
    "    def decorator(func):\n",
    "        def wrapped(*args, **kwargs):\n",
    "            if os.path.exists(filename) and not force_calc:\n",
    "                print(f'{func.__name__}: cache file {filename} found! Skip calculations')\n",
    "                if not ignore_if_exist:\n",
    "                    with open(filename, 'rb') as f:\n",
    "                        result = pickle.load(f)\n",
    "                else:\n",
    "                    result = None\n",
    "            else:\n",
    "                print(f'{func.__name__}: RECALC {filename}.\\nargs: {\", \".join(args)}, kwargs: {\", \".join([f\"{k}={v}\" for k, v in kwargs.items()])}')\n",
    "                result = func(*args, **kwargs)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(result, f)\n",
    "            return result\n",
    "        return wrapped\n",
    "    return decorator\n",
    "\n",
    "def calc_avranks(results):  # {dataset: {classifier: accuracy}}\n",
    "    ranks = defaultdict(list)\n",
    "    for dataset, classifier_accuracy in results.items():\n",
    "        if type(dataset) == tuple:\n",
    "            dataset = '_'.join([str(x) for x in dataset])\n",
    "        classifiers, accuracies = zip(*list(classifier_accuracy.items()))\n",
    "        for classifier, rank in zip(classifiers, rankdata(accuracies)):\n",
    "            ranks[classifier].append(rank)\n",
    "    ranks = {k: np.mean(v) for k, v in sorted(ranks.items(), key=lambda x: x[0])}\n",
    "    return list(ranks.values()), list(ranks.keys()), len(results)\n",
    "\n",
    "def ytrue_to_partition(y_true):\n",
    "    partition = defaultdict(list)\n",
    "    for idx, class_ in enumerate(y_true):\n",
    "        partition[class_].append(idx)\n",
    "    return list(partition.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_RESULTS_ROOT = '../../cache/kkmeans_init_datasets'\n",
    "datasets = [\n",
    "    'cora_DB', 'cora_EC', 'cora_HA', 'cora_HCI', 'cora_IR', 'cora_Net',\n",
    "    'dolphins',\n",
    "    'eu-core',\n",
    "    'eurosis',\n",
    "    'football',\n",
    "    'karate',\n",
    "    'news_2cl1_0.1', 'news_2cl2_0.1', 'news_2cl3_0.1',\n",
    "    'news_3cl1_0.1', 'news_3cl2_0.1', 'news_3cl3_0.1',\n",
    "    'news_5cl1_0.1', 'news_5cl2_0.1', 'news_5cl3_0.1',\n",
    "    'polblogs',\n",
    "    'polbooks',\n",
    "    'sp_school_day_1', 'sp_school_day_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{CACHE_ROOT}/datasets_inits_bestparam_byari_individual_0.1.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "with open(f'{CACHE_ROOT}/datasets_modularity_0.1.pkl', 'rb') as f:\n",
    "    modularity_results = pickle.load(f)\n",
    "    \n",
    "for key in list(results.keys()):\n",
    "    if key[0] not in datasets:\n",
    "        del results[key]\n",
    "        \n",
    "for key in list(results.keys()):\n",
    "    if key[0] not in datasets:\n",
    "        del modularity_results[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_modularity_any3 = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))  # {dataset: {graphidx: {kernel_name: best_ari}}}\n",
    "for (dataset, kernel_name, graph_idx), si_ari in results.items():\n",
    "    results_modularity_any3[dataset][graph_idx][kernel_name] = si_ari['modularity_any3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(dataset_name, feature, G, partition, sp, max_clique):\n",
    "    # graph-independent features\n",
    "    n, k, p_in, p_out = dataset_name\n",
    "    if feature == 'n':\n",
    "        return n\n",
    "    elif feature == 'k':\n",
    "        return k\n",
    "    elif feature == 'p_in':\n",
    "        return p_in\n",
    "    elif feature == 'p_out':\n",
    "        return p_out\n",
    "    elif feature == 'n/k':\n",
    "        return n / k\n",
    "    elif feature == 'p_in/p_out':\n",
    "        return p_in / p_out\n",
    "    \n",
    "    elif feature == 'log(n)':\n",
    "        return n\n",
    "    elif feature == 'log(k)':\n",
    "        return k\n",
    "    elif feature == 'log(p_in)':\n",
    "        return p_in\n",
    "    elif feature == 'log(p_out)':\n",
    "        return p_out\n",
    "    elif feature == 'log(n/k)':\n",
    "        return n / k\n",
    "    elif feature == 'log(p_in/p_out)':\n",
    "        return p_in / p_out\n",
    "    \n",
    "    elif feature == 'n/k * p_in/p_out':\n",
    "        return (n / k) * (p_in / p_out)\n",
    "    elif feature == 'log(n)/k * p_in/p_out':\n",
    "        return np.log(n) / k * (p_in / p_out)\n",
    "    elif feature == 'log(n/k) * p_in/p_out':\n",
    "        return np.log(n / k) * (p_in / p_out)\n",
    "    elif feature == 'log(n/k * p_in/p_out)':\n",
    "        return np.log((n / k) * (p_in / p_out))\n",
    "    \n",
    "    elif feature == 'sbm_neighbour_score':\n",
    "        return sbm_neighbour_score(int(n), int(k), p_in, p_out)\n",
    "    \n",
    "    # graph-dependant features\n",
    "    elif feature == 'modularity':\n",
    "        return nx.community.modularity(G, partition)\n",
    "    elif feature == 'diameter':\n",
    "        return nx.diameter(G)\n",
    "    elif feature == 'density':\n",
    "        return nx.density(G)\n",
    "    elif feature == 'avg_deg':\n",
    "        return np.mean(G.degree)\n",
    "    elif feature == 'std_deg':\n",
    "        return np.std(G.degree)\n",
    "    elif feature == 'avg(deg | deg > avg_deg)':\n",
    "        deg = np.array(G.degree)\n",
    "        return np.mean(deg[deg > np.mean(deg)])\n",
    "    elif feature == 'median_deg':\n",
    "        return np.median(G.degree)\n",
    "    elif feature == 'max_deg':\n",
    "        return np.max(G.degree)\n",
    "    elif feature == 'avg_sp':\n",
    "        return nx.average_shortest_path_length(G)\n",
    "    elif feature == 'std_sp':\n",
    "        return np.std(sp)\n",
    "    elif feature == 'median_sp':\n",
    "        return np.median(sp)\n",
    "    elif feature == 'max_sp':\n",
    "        return np.max(sp)\n",
    "    elif feature == 'max_clique':\n",
    "        return max_clique\n",
    "    elif feature == 'max_clique/(n/k)':\n",
    "        return max_clique/(n/k)\n",
    "    else:\n",
    "        raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'n', 'k', 'p_in', 'p_out', 'n/k', 'p_in/p_out',\n",
    "    'log(n)/k * p_in/p_out', 'n/k * p_in/p_out', 'log(n/k) * p_in/p_out', 'log(n/k * p_in/p_out)',\n",
    "    'sbm_neighbour_score',\n",
    "    'modularity', 'diameter', 'density', \n",
    "    'avg_deg', 'std_deg', 'avg(deg | deg > avg_deg)', 'median_deg', 'max_deg',\n",
    "    'avg_sp', 'std_sp', 'median_sp', 'max_sp', \n",
    "    'max_clique', 'max_clique/(n/k)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9a663b93b94e67bb4b8a0bead767ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapper: cache file ../../cache/cache/feature_importance/cora_DB.pkl found! Skip calculations\n",
      "wrapper: cache file ../../cache/cache/feature_importance/cora_EC.pkl found! Skip calculations\n",
      "wrapper: cache file ../../cache/cache/feature_importance/cora_HA.pkl found! Skip calculations\n",
      "wrapper: RECALC ../../cache/cache/feature_importance/cora_HCI.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: cache file ../../cache/cache/feature_importance/cora_IR.pkl found! Skip calculations\n",
      "wrapper: RECALC ../../cache/cache/feature_importance/cora_Net.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/dolphins.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/eu-core.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/eurosis.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/football.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/karate.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_2cl1_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_2cl2_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_2cl3_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_3cl1_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_3cl2_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_3cl3_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_5cl1_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_5cl2_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/news_5cl3_0.1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/polblogs.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/polbooks.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/sp_school_day_1.pkl.\n",
      "args: , kwargs: \n",
      "wrapper: RECALC ../../cache/cache/feature_importance/sp_school_day_2.pkl.\n",
      "args: , kwargs: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_column(column):\n",
    "    @load_or_calc_and_save(f'{CACHE_ROOT}/feature_importance/{column}.pkl')\n",
    "    def wrapper():\n",
    "        X, ya, yr = [], [], []\n",
    "        (A, partition), info = Datasets()[column]\n",
    "        n, k, p_in, p_out = info['n'], info['k'], info['p_in'], info['p_out']\n",
    "        G = nx.from_numpy_matrix(A)\n",
    "        partition = ytrue_to_partition(partition) \n",
    "        sp = [l for u in G for v, l in nx.single_source_shortest_path_length(G, u).items()]\n",
    "        max_clique = len(clique.max_clique(G))\n",
    "        features = [extract_feature((n, k, p_in, p_out), feature_name, G, partition, sp, max_clique) for feature_name in feature_names]\n",
    "        for graph_idx in range(7):\n",
    "            graph_ari = [v for k, v in sorted(list(results_modularity_any3[column][graph_idx].items()), key=lambda x: x[0])]\n",
    "            graph_ranks = calc_avranks({0: results_modularity_any3[column][graph_idx]})[0]\n",
    "\n",
    "            X.append(features)\n",
    "            ya.append(graph_ari)\n",
    "            yr.append(graph_ranks)\n",
    "        return X, ya, yr\n",
    "    \n",
    "    return wrapper()\n",
    "    \n",
    "Xy_list = Parallel(n_jobs=1)(delayed(prepare_column)(column) for column in tqdm(results_modularity_any3.keys()))\n",
    "\n",
    "X, y, X_train, y_train, X_val, y_val = [], [], [], [], [], []\n",
    "for Xi, _, yi in Xy_list:\n",
    "    X.extend(Xi)\n",
    "    y.extend(yi > (np.max(yi, axis=1, keepdims=True) - 0.05))\n",
    "    X_train.extend(Xi[:5])\n",
    "    y_train.extend(yi[:5] > (np.max(yi[:5], axis=1, keepdims=True) - 0.05))\n",
    "    X_val.extend(Xi[5:])\n",
    "    y_val.extend(yi[5:] > (np.max(yi[5:], axis=1, keepdims=True) - 0.05))\n",
    "    \n",
    "X, y, X_train, y_train, X_val, y_val = np.array(X), np.array(y), np.array(X_train), np.array(y_train), np.array(X_val), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00600000e+03, 7.00000000e+00, 2.28103279e-02, 2.95176881e-03,\n",
       "       1.43714286e+02, 7.72768107e+00, 7.63245103e+00, 1.11057816e+03,\n",
       "       3.83897842e+01, 7.01263603e+00, 7.63662712e-01, 4.30491183e-01,\n",
       "       1.30000000e+01, 6.24116001e-03, 2.54386183e+02, 3.22101079e+02,\n",
       "       6.30000000e+02, 2.55000000e+01, 1.00500000e+03, 4.86076971e+00,\n",
       "       1.61001160e+00, 5.00000000e+00, 1.30000000e+01, 7.00000000e+00,\n",
       "       4.87077535e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg(deg | deg &gt; avg_deg)</td>\n",
       "      <td>0.141215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_deg</td>\n",
       "      <td>0.131186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_deg</td>\n",
       "      <td>0.102778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std_deg</td>\n",
       "      <td>0.098875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median_deg</td>\n",
       "      <td>0.083914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n</td>\n",
       "      <td>0.052073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log(n/k * p_in/p_out)</td>\n",
       "      <td>0.046110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n/k * p_in/p_out</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n/k</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_clique/(n/k)</td>\n",
       "      <td>0.022975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max_clique</td>\n",
       "      <td>0.022543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p_in</td>\n",
       "      <td>0.022157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>log(n/k) * p_in/p_out</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>k</td>\n",
       "      <td>0.021025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sbm_neighbour_score</td>\n",
       "      <td>0.019922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>log(n)/k * p_in/p_out</td>\n",
       "      <td>0.019543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p_in/p_out</td>\n",
       "      <td>0.019220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p_out</td>\n",
       "      <td>0.017924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>avg_sp</td>\n",
       "      <td>0.016708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>density</td>\n",
       "      <td>0.016271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>modularity</td>\n",
       "      <td>0.016051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>std_sp</td>\n",
       "      <td>0.013741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_sp</td>\n",
       "      <td>0.011743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diameter</td>\n",
       "      <td>0.011192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>median_sp</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "0   avg(deg | deg > avg_deg)    0.141215\n",
       "1                    avg_deg    0.131186\n",
       "2                    max_deg    0.102778\n",
       "3                    std_deg    0.098875\n",
       "4                 median_deg    0.083914\n",
       "5                          n    0.052073\n",
       "6      log(n/k * p_in/p_out)    0.046110\n",
       "7           n/k * p_in/p_out    0.042857\n",
       "8                        n/k    0.025500\n",
       "9           max_clique/(n/k)    0.022975\n",
       "10                max_clique    0.022543\n",
       "11                      p_in    0.022157\n",
       "12     log(n/k) * p_in/p_out    0.021390\n",
       "13                         k    0.021025\n",
       "14       sbm_neighbour_score    0.019922\n",
       "15     log(n)/k * p_in/p_out    0.019543\n",
       "16                p_in/p_out    0.019220\n",
       "17                     p_out    0.017924\n",
       "18                    avg_sp    0.016708\n",
       "19                   density    0.016271\n",
       "20                modularity    0.016051\n",
       "21                    std_sp    0.013741\n",
       "22                    max_sp    0.011743\n",
       "23                  diameter    0.011192\n",
       "24                 median_sp    0.003087"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=100)\n",
    "estimator.fit(X_train, y_train)\n",
    "pd.DataFrame([{'feature': k, 'importance': v} for k, v in sorted(zip(feature_names, estimator.feature_importances_), key=lambda x: -x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "[('n', False), ('k', False), ('p_in', False), ('p_out', False), ('n/k', False), ('p_in/p_out', False), ('log(n)/k * p_in/p_out', False), ('n/k * p_in/p_out', False), ('log(n/k) * p_in/p_out', False), ('log(n/k * p_in/p_out)', False), ('sbm_neighbour_score', False), ('modularity', False), ('diameter', False), ('density', False), ('avg_deg', False), ('std_deg', True), ('avg(deg | deg > avg_deg)', True), ('median_deg', False), ('max_deg', False), ('avg_sp', False), ('std_sp', False), ('median_sp', False), ('max_sp', False), ('max_clique', False), ('max_clique/(n/k)', False)]\n",
      "[('n', 4), ('k', 20), ('p_in', 8), ('p_out', 16), ('n/k', 19), ('p_in/p_out', 15), ('log(n)/k * p_in/p_out', 17), ('n/k * p_in/p_out', 6), ('log(n/k) * p_in/p_out', 12), ('log(n/k * p_in/p_out)', 7), ('sbm_neighbour_score', 11), ('modularity', 23), ('diameter', 22), ('density', 13), ('avg_deg', 2), ('std_deg', 1), ('avg(deg | deg > avg_deg)', 1), ('median_deg', 5), ('max_deg', 3), ('avg_sp', 14), ('std_sp', 18), ('median_sp', 24), ('max_sp', 21), ('max_clique', 9), ('max_clique/(n/k)', 10)]\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=100)\n",
    "selector = RFE(estimator, n_features_to_select=2, verbose=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "print(list(zip(feature_names, selector.support_)))\n",
    "print(list(zip(feature_names, selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>to choose</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg(deg | deg &gt; avg_deg)</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>std_deg</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_deg</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>max_deg</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>median_deg</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n/k * p_in/p_out</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>log(n/k * p_in/p_out)</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_in</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>max_clique</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_clique/(n/k)</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sbm_neighbour_score</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>log(n/k) * p_in/p_out</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>density</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_sp</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p_in/p_out</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_out</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log(n)/k * p_in/p_out</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>std_sp</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n/k</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max_sp</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>diameter</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modularity</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>median_sp</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  to choose  rank\n",
       "16  avg(deg | deg > avg_deg)       True     1\n",
       "15                   std_deg       True     1\n",
       "14                   avg_deg      False     2\n",
       "18                   max_deg      False     3\n",
       "0                          n      False     4\n",
       "17                median_deg      False     5\n",
       "7           n/k * p_in/p_out      False     6\n",
       "9      log(n/k * p_in/p_out)      False     7\n",
       "2                       p_in      False     8\n",
       "23                max_clique      False     9\n",
       "24          max_clique/(n/k)      False    10\n",
       "10       sbm_neighbour_score      False    11\n",
       "8      log(n/k) * p_in/p_out      False    12\n",
       "13                   density      False    13\n",
       "19                    avg_sp      False    14\n",
       "5                 p_in/p_out      False    15\n",
       "3                      p_out      False    16\n",
       "6      log(n)/k * p_in/p_out      False    17\n",
       "20                    std_sp      False    18\n",
       "4                        n/k      False    19\n",
       "1                          k      False    20\n",
       "22                    max_sp      False    21\n",
       "12                  diameter      False    22\n",
       "11                modularity      False    23\n",
       "21                 median_sp      False    24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(feature_names, selector.support_, selector.ranking_), columns=['feature', 'to choose', 'rank']).sort_values('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=100)\n",
    "estimator.fit(X_train[:, selector.support_], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg(deg | deg > avg_deg)\t0.530\n",
      "std_deg\t0.470\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([f'{k}\\t{v:.3f}' for k, v in sorted(zip(np.array(feature_names)[selector.support_], estimator.feature_importances_), key=lambda x: -x[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X_val[:, selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val.ravel(), y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675276752767528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val.ravel(), y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
